{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple LINEAR REGRESSION: y = intercept + coef1(x1) + coef2(x2) + coef3(x3) + errorterm\n",
    "- Linear Regression function parameter:\n",
    "    1. X:np.array -> [[1,2,3],[4,5,6]] \"two-Dimension Array\"\n",
    "    2. y:np.array  -> [4,5,6] 'One-Dimension Array\"\n",
    "    * returns -> [coef1, coef2,coef3] and intercept\n",
    "- Predictions function parameter:\n",
    "    1. coefficients: np.array \"One-Dimension\"\n",
    "    2. intercept: float\n",
    "    3. X: np.array -> [[1,2,3],[4,5,6]] \"Two-Dimension Array\"\n",
    "    * returns -> predictions:np.array \"one-Dimension array\"\n",
    "- R2 function:\n",
    "    1. y_true: np.array -> [1,2,3]\n",
    "    2. predictions: np.array -> [1,2,3]\n",
    "    * returns -> R2:float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def multiple_linear_regression(X:np.array, y:np.array)-> np.array:\n",
    "   \n",
    "    # Add a column of ones to X for the intercept term\n",
    "    X_extended = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate coefficients (b0, b1, ..., bn) using the normal equation\n",
    "    #np.linalg.inv is calculate the matrix inverse for the\n",
    "    #X_extended.t @ X_extended ; which represents dot function of transpose \n",
    "    #bcs normal equation involves inverse matrix \n",
    "    # and the X.entended.T @ y ; is for calculating the coefficients \n",
    "    coefficients = np.linalg.inv(X_extended.T @ X_extended) @ X_extended.T @ y\n",
    "\n",
    "    # Extract the intercept and coefficients\n",
    "    intercept = coefficients[0]\n",
    "    coefficients = coefficients[1:]\n",
    "\n",
    "    return coefficients, intercept\n",
    "\n",
    "# Example usage:\n",
    "# Replace X_data and y_data with your own data\n",
    "#X_data = np.array([[1, 2], [2, 3], [3, 4]])\n",
    "#y_data = np.array([5, 8, 10])\n",
    "\n",
    "#coefficients, intercept = multiple_linear_regression(X_data, y_data)\n",
    "\n",
    "#print(\"Coefficients:\", coefficients)\n",
    "#print(\"Intercept:\", intercept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula explain \n",
    "Adding a Column of Ones (Intercept):\n",
    "\n",
    "np.c_[np.ones(X.shape[0]), X]: This line creates a new matrix X_extended by adding a column of ones to the input feature matrix X. The column of ones is added to account for the intercept term in the linear regression model.\n",
    "Normal Equation:\n",
    "\n",
    "np.linalg.inv(X_extended.T @ X_extended): This part calculates the inverse of the matrix product of the transpose of X_extended and X_extended. This is a step in solving the normal equation.\n",
    "\n",
    "X_extended.T @ X_extended represents the dot product of the transpose of X_extended with itself. The normal equation involves the inverse of this matrix.\n",
    "\n",
    "np.linalg.inv calculates the matrix inverse.\n",
    "\n",
    "Calculating Coefficients:\n",
    "\n",
    "@ X_extended.T @ y: After obtaining the inverse of the matrix, the code multiplies it by the transpose of X_extended and then by the target variable y.\n",
    "\n",
    "The result of this multiplication gives the coefficients (parameters) for the linear regression model. These coefficients include the intercept (b0) and the slopes for each feature (b1, b2, ..., bn).\n",
    "\n",
    "In summary, the code is solving the normal equation to find the coefficients for a multiple linear regression model. The normal equation provides a closed-form solution to the linear regression problem by directly calculating the coefficients that minimize the sum of squared differences between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction function\n",
    "\n",
    "def predict_multiple_linear_regression(X:np.array, coefficients:np.array, intercept:float)-> np.array:\n",
    "    # Add a column of ones to X for the intercept term\n",
    "    X_extended = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "    # Calculate predictions\n",
    "    y_pred = X_extended @ np.hstack((intercept, coefficients))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# Example usage:\n",
    "# Replace X_data, coefficients, and intercept with your own data\n",
    "#X_data = np.array([[1, 2], [2, 3], [3, 4]])\n",
    "#coefficients = np.array([2, 3])\n",
    "#intercept = 1\n",
    "\n",
    "#predictions = predict_multiple_linear_regression(X_data, coefficients, intercept)\n",
    "\n",
    "#print(\"Input features (X):\")\n",
    "#print(X_data)\n",
    "#print(\"\\nPredicted values:\")\n",
    "#print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compuet r2 function\n",
    "#compute R2 - coef of determination = 1- (SSR/SST)\n",
    "def compute_r2(y_true, y_pred):\n",
    "    residual = y_true - y_pred\n",
    "    mean_y_true = np.mean(y_true)\n",
    "    #** is power of\n",
    "    #total sum of square\n",
    "    total_variance = np.sum((y_true - mean_y_true) ** 2)\n",
    "    #sum of squared errors = SSR\n",
    "    explained_variance = np.sum((residual) ** 2)\n",
    "\n",
    "    r2 = 1- (explained_variance / total_variance)\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REAL DATA APPLICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# using loadtxt()\n",
    "Data = np.loadtxt(\"Startups.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "\n",
    "#display(Data)\n",
    "#print(Data.ndim)\n",
    "#print(Data.shape)\n",
    "#print(Data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Data\n",
    "Data_without_first_row = np.delete(Data, 0, axis=0)\n",
    "shuffled_data = np.random.permutation(Data_without_first_row)\n",
    "#print(\"Original 2D array:\")\n",
    "#print(Data)\n",
    "#print(\"Shuffled copy:\")\n",
    "#print(shuffled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size : 37\n",
      "Testing set size : 12\n"
     ]
    }
   ],
   "source": [
    "#training and testing set size\n",
    "train_size=int(0.75*np.size(shuffled_data,0))\n",
    "test_size=int(0.25*np.size(shuffled_data,0))\n",
    "print(\"Training set size : \"+ str(train_size))\n",
    "print(\"Testing set size : \"+str(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT FEATURES AND PREDICTOR\n",
    "#Getting features from dataset select column number\n",
    "X=shuffled_data[:,[0,1,2]]\n",
    "y=shuffled_data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT TRAIN/TEST (make sure X is 2d array and y is 1d array)\n",
    "#training set split\n",
    "X_train=X[0:train_size,:]\n",
    "X_train = X_train.astype(np.float_)\n",
    "y_train=y[0:train_size]\n",
    "y_train = y_train.flatten()\n",
    "y_train = y_train.astype(np.float_)\n",
    "\n",
    "#testing set split\n",
    "X_test=X[train_size:,:]\n",
    "X_test = X_test.astype(np.float_)\n",
    "Y_test=y[train_size:]\n",
    "Y_test = Y_test.flatten()\n",
    "Y_test = Y_test.astype(np.float_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.77173952 -0.01549975  0.02528518]\n",
      "Intercept: 51898.258181425525\n",
      "R-squared : 0.9569100181557307\n"
     ]
    }
   ],
   "source": [
    "#Find beta coef and Intercept\n",
    "coefficients, intercept = multiple_linear_regression(X_train, y_train)\n",
    "#predictions function\n",
    "predictions = predict_multiple_linear_regression(np.array(X_train), np.array(coefficients), intercept)\n",
    "#Compute R2\n",
    "r2_train = compute_r2(np.array(y_train),predictions)\n",
    "\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"R-squared :\", r2_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicecode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
